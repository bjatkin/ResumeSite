<p>
    Atkinson Initalization is the results of my masters thesis work at BYU.
    This project was done in conjuction with 
    <a href="https://cs.byu.edu/faculty/faculty-directory/david-wingate/" rel="noopener noreferrer" target="_blank">David Wingate</a>
    who served as my adviser and 
    <a href="https://github.com/Populustremuloides" rel="noopener noreferrer" target="_blank">Brian Brown</a>
    who helped with the initial research that let to this idea. Atkinson initalization is a new initalization method
    which was devised to be a more general initalization method capable of handling the vast differences in architecutes
    in moden neural network research. Current research into this method is still ongoing but preliminary results apear
    promising and we look forward to providing the full thesis once it has been completed.
</p>

<component tag="chip" src="../../components/d_chip.html"></component>

<h3>Technologies Levereaged</h3>
<hr>
<div style="display: flex; flex-wrap: wrap;">
    <chip label="Pytorch"></chip>
    <chip label="Google Colab"></chip>
    <chip label="Jupiter Notebooks"></chip>
    <chip label="Numpy"></chip>
    <chip label="Scipy"></chip>
    <chip label="Pandas"></chip>
</div>